# create a summary table of the top 5 words defining each cluster
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:5 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:2 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
gg <- data.frame(cluster_summary$size)
gg <- as.matrix(gg)
names(gg) <- c(cluster_summary$top_words)
sorted <- sort(gg, decreasing = T)
sorted <- sorted[with(sorted,order(-sorted)), ] ## Sorting
sorted <- data.frame(word = names(gg), freq=gg)
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "brown4", low = "brown1") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
sorted <- data.frame(word = names(gg), freq=gg)
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "brown4", low = "brown1") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "brown4", low = "brown1") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "brown4", low = "brown1") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "brown4", low = "brown1") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
sorted <- sort(gg, decreasing = T)
sorted <- data.frame(word = names(sorted), freq=sorted)
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "brown4", low = "brown1") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
cluster_summary
# create a summary table of the top 5 words defining each cluster
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:5 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
cluster_summary
texts <- c("i am member of the XYZ association",
"apply for our open associate position",
"xyz memorial lecture takes place on wednesday",
"vote for the most popular lecturer")
library(tm)
# Step 1: Create corpus
corpus.copy <- corpus <- Corpus(DataframeSource(data.frame(texts)))
# Step 1: Create corpus
corpus.copy <- corpus <- Corpus(DataframeSource(data.frame(texts)))
# Step 1: Create corpus
corpus <- Corpus(DataframeSource(data.frame(texts)))
# Step 1: Create corpus
corpus <- Corpus(DataframeSource(data.frame(texts)))
df_titleSeverity <- rd
df_titleSeverity <- table(severity = as.numeric(df_titleSeverity$severity), moduleName = df_titleSeverity$moduleName)
df_titleSeverity
df_titleSeverity <- as.data.frame(df_titleSeverity)
df <- na.omit(df_titleSeverity)
df <- scale(df)
df_titleSeverity <- rd
df_titleSeverity <- table(severity = as.numeric(df_titleSeverity$severity), moduleName = df_titleSeverity$moduleName)
df_titleSeverity <- as.data.frame(df_titleSeverity)
df <- na.omit(df_titleSeverity)
df <- scale(df)
texts <- c("i am member of the XYZ association",
"apply for our open associate position",
"xyz memorial lecture takes place on wednesday",
"vote for the most popular lecturer")
library(tm)
# Step 1: Create corpus
corpus <- Corpus(DataframeSource(data.frame(texts)))
# Step 1: Create corpus
data.frame(texts)
# Step 1: Create corpus
DataframeSource(data.frame(texts))
# Step 1: Create corpus
?DataframeSource
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:2 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
gg <- data.frame(cluster_summary$size)
gg <- as.matrix(gg)
names(gg) <- c(cluster_summary$top_words)
sorted <- sort(gg, decreasing = T)
sorted <- data.frame(word = names(sorted), freq=sorted)
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "tomato4", low = "tomato") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:3 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
gg <- data.frame(cluster_summary$size)
gg <- as.matrix(gg)
names(gg) <- c(cluster_summary$top_words)
sorted <- sort(gg, decreasing = T)
sorted <- data.frame(word = names(sorted), freq=sorted)
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "tomato4", low = "tomato") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:2 ],
collapse = ", ")
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:2 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
gg <- data.frame(cluster_summary$size)
gg <- as.matrix(gg)
names(gg) <- c(cluster_summary$top_words)
sorted <- sort(gg, decreasing = T)
sorted <- data.frame(word = names(sorted), freq=sorted)
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "tomato4", low = "tomato") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
wordcloud(words = names(cluster_words[[1]]),
freq = cluster_words[[1]],
random.order = F,
colors=brewer.pal(8, "Set2"),
main = "Top words in cluster 100")
?t
knitr::opts_chunk$set(echo = TRUE)
library(dplyr) #funny library name
library(ggplot2)
library(textmineR)
library(tm)
library(rvest)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
# just for fun...
# initiating raw data
rawData <- read.csv("csv/all.csv")
rawData$created_at <- as.Date(rawData$created_at, format="%Y-%m-%d")
rawData$disclosed_at <- as.Date(rawData$disclosed_at, format="%Y-%m-%d")
rawData$reportedAt <- strptime(rawData$reportedAt, "%Y-%m-%d %H:%M:%S")
basic.data <- data.frame(rawData$disclosed_at)
titleCorpus <- VCorpus(VectorSource(rawData$title))
clean <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, stopwords("en"))
return(corpus)
}
cleanFunctionalityData <- clean(titleCorpus)
# stemming
stemFunc <- content_transformer(function(x){
paste(sapply(words(x),stemDocument),collapse = " ")
})
# stemmed functionality string
stemFnData <- tm_map(cleanFunctionalityData, stemFunc)
dtm <- TermDocumentMatrix(stemFnData)
mat <- as.matrix(dtm)
# sort by frequency and print the first 20]
sortedData <- sort(rowSums(mat), decreasing = TRUE )
first20 <- sortedData[1:20];
d <- data.frame(word = names(first20), freq=first20)
# head(d, 20)
## Find a range of y's that'll leave sufficient space above the tallest bar
bpFreqWord <- barplot(sortedData[1:20]
,main='Most Frequent Word in Titles'
,horiz=TRUE
,xlab="Occurences"
,ylab="Word"
,col=rev(brewer.pal(9, "YlOrRd"))
,las=2
,cex.names=0.8)
ggplot(data = d  , aes(x = word, y = freq, fill=-freq)) +
geom_bar(stat="identity") +
scale_color_gradient2(low = "lightblue", high = "darkblue", midpoint=75) +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')
df <- data.frame(rawData$title, rawData$severity)
names(df) <- c("title","severity")
df <- mutate(df, id = rownames(df))
df <- df[!(is.na(df$title) | df$title==""), ]
# create a document term matrix
dtm <- CreateDtm(doc_vec = df$title, # character vector of documents
doc_names = df$id, # document names
ngram_window = c(1, 2), # minimum and maximum n-gram length
stopword_vec = c(tm::stopwords("english"), # stopwords from tm
tm::stopwords("SMART")), # this is the default value
lower = TRUE, # lowercase - this is the default value
remove_punctuation = TRUE, # punctuation - this is the default
remove_numbers = TRUE, # numbers - this is the default
verbose = FALSE, # Turn off status bar for this demo
cpus = 2) # default is all available cpus on the system
# construct the matrix of term counts to get the IDF vector
tf_mat <- TermDocFreq(dtm)
# TF-IDF and cosine similarity
tfidf <- t(dtm[ , tf_mat$term ]) * tf_mat$idf
tfidf <- t(tfidf)
csim <- tfidf / sqrt(rowSums(tfidf * tfidf))
csim <- csim %*% t(csim)
cdist <- as.dist(1 - csim)
hc <- hclust(cdist, method="ward.D")
clustering <- cutree(hc, 10)
plot(hc, main = "Hierarchical clustering of 100 NIH grant abstracts",
ylab = "", xlab = "", yaxt = "n")
# rect.hclust(hc, 10, border = "red") #uncomment to see the hierarchical clustering
p_words <- colSums(dtm) / sum(dtm)
cluster_words <- lapply(unique(clustering), function(x){
rows <- dtm[ clustering == x , ]
# for memory's sake, drop all words that don't appear in the cluster
rows <- rows[ , colSums(rows) > 0 ]
colSums(rows) / sum(rows) - p_words[ colnames(rows) ]
})
# create a summary table of the top 5 words defining each cluster
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:5 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
cluster_summary
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:2 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
gg <- data.frame(cluster_summary$size)
gg <- as.matrix(gg)
names(gg) <- c(cluster_summary$top_words)
sorted <- sort(gg, decreasing = T)
sorted <- data.frame(word = names(sorted), freq=sorted)
ggplot(data =sorted  , aes(x=reorder(word,freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "tomato4", low = "tomato") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
wordcloud(words = names(cluster_words[[1]]),
freq = cluster_words[[1]],
random.order = F,
colors=brewer.pal(8, "Set2"),
main = "Top words in cluster 100")
dtm <- TermDocumentMatrix(stemFnData)
m = as.matrix(t(dtm))
# get word counts in decreasing order
word_freqs = sort(colSums(m), decreasing=TRUE)
# create a data frame with words and their frequencies
dm = data.frame(word=names(word_freqs), freq=word_freqs)
dm$word
# plot wordcloud
wordcloud(dm$word, dm$freq, random.order=FALSE, colors=brewer.pal(8, "Dark2"))
ggplot(data = d  , aes(x = word, y = freq, fill=-freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_color_gradient2(low = "lightblue", high = "darkblue", midpoint=75) +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')
# head(d, 20)
## Find a range of y's that'll leave sufficient space above the tallest bar
bpFreqWord <- barplot(sortedData[1:20]
,main='Most Frequent Word in Titles'
,horiz=TRUE
,xlab="Occurences"
,ylab="Word"
,col=rev(brewer.pal(9, "YlOrRd"))
,las=2
,cex.names=0.8)
wordcloud(words = names(cluster_words[[10]]),
freq = cluster_words[[1]],
random.order = F,
colors=brewer.pal(8, "Set2"),
main = "Top words in cluster 100")
wordcloud(words = names(cluster_words[[10]]),
freq = cluster_words[[10]],
random.order = F,
colors=brewer.pal(8, "Set2"),
main = "Top words in cluster 100")
ggplot(data =sorted  , aes(x=reorder(word,-freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "tomato4", low = "tomato") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
rawData <- read.csv("csv/all.csv")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr) #funny library name
library(ggplot2)
library(textmineR)
library(tm)
library(rvest)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
# just for fun...
# initiating raw data
rawData <- read.csv("csv/synk")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr) #funny library name
library(ggplot2)
library(textmineR)
library(tm)
library(rvest)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
# just for fun...
# initiating raw data
rawData <- read.csv("csv/synk.csv")
basic.data <- data.frame(rawData$disclosed_at)
titleCorpus <- VCorpus(VectorSource(rawData$vulnerabilities))
clean <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, stopwords("en"))
return(corpus)
}
cleanFunctionalityData <- clean(titleCorpus)
# stemming
stemFunc <- content_transformer(function(x){
paste(sapply(words(x),stemDocument),collapse = " ")
})
# stemmed functionality string
stemFnData <- tm_map(cleanFunctionalityData, stemFunc)
dtm <- TermDocumentMatrix(stemFnData)
mat <- as.matrix(dtm)
# sort by frequency and print the first 20]
sortedData <- sort(rowSums(mat), decreasing = TRUE )
first20 <- sortedData[1:20];
d <- data.frame(word = names(first20), freq=first20)
# head(d, 20)
## Find a range of y's that'll leave sufficient space above the tallest bar
bpFreqWord <- barplot(sortedData[1:20]
,main='Most Frequent Word in Titles'
,horiz=TRUE
,xlab="Occurences"
,ylab="Word"
,col=rev(brewer.pal(9, "YlOrRd"))
,las=2
,cex.names=0.8)
ggplot(data = d  , aes(x = word, y = freq, fill=-freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_color_gradient2(low = "lightblue", high = "darkblue", midpoint=75) +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')
df <- data.frame(rawData$title, rawData$severity)
df <- data.frame(rawData$vulerabilities, rawData$severity)
df <- data.frame(rawData$vulnerabilities, rawData$severity)
names(df) <- c("title","severity")
df <- mutate(df, id = rownames(df))
df <- df[!(is.na(df$title) | df$title==""), ]
# create a document term matrix
dtm <- CreateDtm(doc_vec = df$title, # character vector of documents
doc_names = df$id, # document names
ngram_window = c(1, 2), # minimum and maximum n-gram length
stopword_vec = c(tm::stopwords("english"), # stopwords from tm
tm::stopwords("SMART")), # this is the default value
lower = TRUE, # lowercase - this is the default value
remove_punctuation = TRUE, # punctuation - this is the default
remove_numbers = TRUE, # numbers - this is the default
verbose = FALSE, # Turn off status bar for this demo
cpus = 2) # default is all available cpus on the system
# construct the matrix of term counts to get the IDF vector
tf_mat <- TermDocFreq(dtm)
# TF-IDF and cosine similarity
tfidf <- t(dtm[ , tf_mat$term ]) * tf_mat$idf
tfidf <- t(tfidf)
csim <- tfidf / sqrt(rowSums(tfidf * tfidf))
csim <- csim %*% t(csim)
cdist <- as.dist(1 - csim)
hc <- hclust(cdist, method="ward.D")
clustering <- cutree(hc, 10)
plot(hc, main = "Hierarchical clustering of 100 NIH grant abstracts",
ylab = "", xlab = "", yaxt = "n")
# rect.hclust(hc, 10, border = "red") #uncomment to see the hierarchical clustering
p_words <- colSums(dtm) / sum(dtm)
cluster_words <- lapply(unique(clustering), function(x){
rows <- dtm[ clustering == x , ]
# for memory's sake, drop all words that don't appear in the cluster
rows <- rows[ , colSums(rows) > 0 ]
colSums(rows) / sum(rows) - p_words[ colnames(rows) ]
})
# create a summary table of the top 5 words defining each cluster
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:5 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
cluster_summary
cluster_summary <- data.frame(cluster = unique(clustering),
size = as.numeric(table(clustering)),
top_words = sapply(cluster_words, function(d){
paste(
names(d)[ order(d, decreasing = TRUE) ][ 1:2 ],
collapse = ", ")
}),
stringsAsFactors = FALSE)
gg <- data.frame(cluster_summary$size)
gg <- as.matrix(gg)
names(gg) <- c(cluster_summary$top_words)
sorted <- sort(gg, decreasing = T)
sorted <- data.frame(word = names(sorted), freq=sorted)
ggplot(data =sorted  , aes(x=reorder(word,-freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "tomato4", low = "tomato") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+5))
ggplot(data =sorted  , aes(x=reorder(word,-freq), y=freq, fill=freq)) +
geom_bar(stat="identity") +
coord_flip() +
scale_fill_gradient(high = "tomato4", low = "tomato") +
labs(title = 'Word Occurences on Reports`s Title',
x = 'Words',
y = 'Occurences')  +
geom_text(aes(label=sprintf("%1.0f", freq), y=freq+10))
dtm <- TermDocumentMatrix(stemFnData)
m = as.matrix(t(dtm))
# get word counts in decreasing order
word_freqs = sort(colSums(m), decreasing=TRUE)
# create a data frame with words and their frequencies
dm = data.frame(word=names(word_freqs), freq=word_freqs)
dm$word
# plot wordcloud
wordcloud(dm$word, dm$freq, random.order=FALSE, colors=brewer.pal(8, "Dark2"))
unique(rawData$moduleName)
length(unique(rawData$moduleName))
